{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d756789",
   "metadata": {},
   "source": [
    "# An√°lisis de Ventas con PySpark\n",
    "Este notebook realiza an√°lisis de datos de ventas usando Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6147ab",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Importar configuraciones\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('./src'))\n",
    "os.makedirs(\"resultados\", exist_ok=True)\n",
    "\n",
    "from config.spark_config import SparkSession\n",
    "from etl.transformaciones import TransformacionesVentas\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.getActiveSession()\n",
    "if spark:\n",
    "    spark.stop()\n",
    "    \n",
    "# Inicializar Spark\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"AnalisisVentas-Notebook\") \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()\n",
    "transformaciones = TransformacionesVentas(spark)\n",
    "spark.conf.get(\"spark.sql.catalogImplementation\")\n",
    "\n",
    "# Cargar datos\n",
    "ventas_df, productos_df = transformaciones.cargar_datos()\n",
    "\n",
    "print(\"üìä Vista previa de ventas:\")\n",
    "ventas_df.show(5)\n",
    "\n",
    "print(\"\\nüì¶ Vista previa de productos:\")\n",
    "productos_df.show(5)\n",
    "\n",
    "print(f\"\\nTotal ventas: {ventas_df.count()}\")\n",
    "print(f\"Total productos: {productos_df.count()}\")\n",
    "\n",
    "# Esquema de datos\n",
    "print(\"Esquema ventas:\")\n",
    "ventas_df.printSchema()\n",
    "\n",
    "print(\"\\nEsquema productos:\")\n",
    "productos_df.printSchema()\n",
    "\n",
    "# Calcular m√©tricas\n",
    "ventas_completas_df, metricas_df = transformaciones.calcular_metricas(ventas_df, productos_df)\n",
    "\n",
    "print(\"üìà M√©tricas por categor√≠a:\")\n",
    "metricas_df.show()\n",
    "\n",
    "# An√°lisis temporal\n",
    "analisis_temporal_df = transformaciones.analisis_temporal(ventas_df)\n",
    "\n",
    "print(\"üìÖ An√°lisis por fecha:\")\n",
    "analisis_temporal_df.show()\n",
    "\n",
    "\n",
    "# Top clientes\n",
    "top_clientes_df = transformaciones.top_clientes(ventas_df, top_n=5)\n",
    "\n",
    "print(\"üëë Top 5 clientes:\")\n",
    "top_clientes_df.show()\n",
    "\n",
    "# An√°lisis adicional: Ventas por producto\n",
    "ventas_por_producto = ventas_completas_df.groupBy(\"nombre\", \"categoria\") \\\n",
    "    .agg(\n",
    "        F.sum(\"cantidad\").alias(\"unidades_vendidas\"),\n",
    "        F.sum(\"venta_total\").alias(\"ingresos\"),\n",
    "        F.round(F.avg(\"precio_unitario\"), 2).alias(\"precio_promedio\")\n",
    "    ) \\\n",
    "    .orderBy(F.desc(\"ingresos\"))\n",
    "\n",
    "print(\"üèÜ Productos m√°s vendidos:\")\n",
    "ventas_por_producto.show()\n",
    "\n",
    "# Visualizaci√≥n (si matplotlib est√° disponible)\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    # Convertir a pandas para visualizaci√≥n\n",
    "    metricas_pandas = metricas_df.toPandas()\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(metricas_pandas['categoria'], metricas_pandas['ingresos_totales'])\n",
    "    plt.title('Ingresos por Categor√≠a')\n",
    "    plt.xlabel('Categor√≠a')\n",
    "    plt.ylabel('Ingresos Totales')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"Matplotlib no disponible para visualizaci√≥n\")\n",
    "\n",
    "# Esquema y Contenido\n",
    "metricas_df.printSchema()\n",
    "metricas_df.show()\n",
    "\n",
    "# Modo no profesional\n",
    "# Guardar resultados\n",
    "print(\"üíæ Guardando resultados...\")\n",
    "\n",
    "# Guardar como Parquet (formato optimizado para Spark)\n",
    "metricas_df.write.mode(\"overwrite\").parquet(\"file:///home/hadoop/proyecto-spark-vscode/resultados/metricas_ventas.parquet\")\n",
    "ventas_completas_df.write.mode(\"overwrite\").parquet(\"file:///home/hadoop/proyecto-spark-vscode/resultados/ventas_completas.parquet\")\n",
    "\n",
    "print(\"‚úÖ Resultados guardados en formato Parquet\")\n",
    "\n",
    "# Modo din√°mica y portable\n",
    "import os\n",
    "\n",
    "print(\"üíæ Guardando resultados...\")\n",
    "\n",
    "# Obtener ruta base del proyecto din√°micamente\n",
    "project_root = os.getcwd()\n",
    "\n",
    "# Carpeta resultados\n",
    "output_dir = os.path.join(project_root, \"resultados\")\n",
    "\n",
    "# Crear carpeta si no existe\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Convertir a formato que Spark entiende\n",
    "output_uri = f\"file://{output_dir}\"\n",
    "\n",
    "# Guardar\n",
    "metricas_df.write.mode(\"overwrite\").parquet(\n",
    "    f\"{output_uri}/metricas_ventas.parquet\"\n",
    ")\n",
    "\n",
    "ventas_completas_df.write.mode(\"overwrite\").parquet(\n",
    "    f\"{output_uri}/ventas_completas.parquet\"\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Resultados guardados en formato Parquet\")\n",
    "\n",
    "# Modo clasico en local\n",
    "os.makedirs(\"resultados\", exist_ok=True)\n",
    "\n",
    "metricas_df.write.mode(\"overwrite\").parquet(\"resultados/metricas_ventas.parquet\")\n",
    "ventas_completas_df.write.mode(\"overwrite\").parquet(\"resultados/ventas_completas.parquet\")\n",
    "\n",
    "# Trabajar con Hive (si est√° configurado)\n",
    "try:\n",
    "    # Crear tabla Hive temporal\n",
    "    ventas_completas_df.createOrReplaceTempView(\"ventas_completas\")\n",
    "    \n",
    "    # Consulta SQL\n",
    "    print(\"üîç Consulta SQL a trav√©s de Hive:\")\n",
    "    resultado_sql = spark.sql(\"\"\"\n",
    "        SELECT categoria, \n",
    "               SUM(venta_total) as ingresos_totales,\n",
    "               AVG(precio_unitario) as precio_promedio\n",
    "        FROM ventas_completas\n",
    "        GROUP BY categoria\n",
    "        ORDER BY ingresos_totales DESC\n",
    "    \"\"\")\n",
    "    \n",
    "    resultado_sql.show()\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Hive no disponible: {e}\")\n",
    "\n",
    "# Detener Spark\n",
    "from config.spark_config import detener_spark_session\n",
    "detener_spark_session(spark)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
